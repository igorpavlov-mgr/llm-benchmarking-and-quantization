# llm-benchmarking-and-quantization
Compare inference speed and optimization trade-offs across LLMs using transformers, ONNX, quantization, and Cohere Command R+
